# CHAPTER 2: 프로그램이 실행되었지만, 뭐가 뭔지 하나도 모르겠다

Chapter 1을 통해 사람이 이해할 수 있는 문자열 Source Code가 CPU를 위한 기계 명령어로 변환되는 과정을 살펴보았다.  
이번 장에서는 프로그램이 실행되었을 때, 운영 체제와 프로세스, 스레드가 어떻게 작동하는지에 대해 알아본다.

### 1. 운영 체제, 프로세스, 스레드의 근본 이해하기
CPU 입장에서 생각해보면 '스레드', '프로세스', '운영 체제' 란 개념을 알 수 없다.  
CPU는 단순히 명령어를 실행하는 장치일 뿐이다. CPU는 메모리에서 명령어를 읽고, 그 명령어에 따라 연산을 수행한다.  
CPU가 명령어를 가져와 실행하는 과정은 다음과 같다.
1. 명령어 인출
2. 명령어 실행
3. 다음 명령어 인출

위와 같은 **명령어 사이클(Instruction Cycle)** 은 CPU가 **프로그램 카운터(Program Counter, PC)** 에 있는 **가상 주소**를 기준으로 명령어를
가져오고(Fetch), 해독하고(Decode), 실행하는 하드웨어 동작을 말한다. 운영 체제(OS)는 개별 명령어 실행을 직접 관리하지 않는다.
대신 어떤 스레드가 언제 CPU를 쓸지(Scheduling) 결정하고, 가상 메모리를 구성하며, 시스템 콜/인터럽트/예외를 처리한다.
CPU가 "다음 명령어"를 가져오는 기준은 PC 다. PC에는 가상 주소가 들어 있으며, MMU/TLB 가 이를 물리 주소로 변환해 I-캐시/메모리에서 명령어를 가져온다.
새 프로그램을 시작할 때는, OS가 실행 파일을 메모리에 매핑하고 레지스터를 초기화한다.
PC는 실행 파일의 엔트리 포인트로 설정되며, 스택 포인터도 초기화된다.

**프로세스** 는 실행 중인 프로그램의 인스턴스이며 고유한 가상 주소 공간을 갖는다.
구조체(structure)로 표현되며, 프로세스의 상태(실행 중, 대기 중 등), 메모리 맵, 파일 디스크립터 등을 포함한다.  
**스레드** 는 프로세스 내 실행 흐름으로, 같은 주소 공간(코드/데이터/힙/파일 디스크립터 등)을 공유한다.
여담으로 스레드를 독립된 개체가 아닌, **자원 공유 수준을 사용자가 정의할 수 있는 실행 컨텍스트(Context of Execution, COE)** 로 생각할 수 있다.

아래는 프로그램이 실행될 때의 개념적 구조를 나타낸 다이어그램이다.
```mermaid
flowchart LR
  %% ===== User Space (Processes & Threads) =====
  subgraph U["User Space"]
    subgraph P1["Process A (Virtual Addr Space)"]
      T1["Thread T1\n(PC, SP, Registers)"]
      T2["Thread T2\n(PC, SP, Registers)"]
    end
    subgraph P2["Process B (Virtual Addr Space)"]
      T3["Thread U1\n(PC, SP, Registers)"]
    end
  end

  %% ===== Kernel (Scheduler, Syscalls, Context Switch) =====
  subgraph K["OS Kernel"]
    RQ["Ready Queue"]
    SCH["Scheduler"]
    CS["Context Switch\n(save/restore PC, SP, regs)"]
    SYSC["Syscall / Interrupt Handler"]
  end

  %% ===== CPU Core & Memory Translation =====
  subgraph C["CPU Core"]
    PC["Program Counter (VA)"]
    IFU["Fetch → Decode → Execute"]
    TLB["MMU / TLB\n(VA → PA)"]
    L1["L1/L2 Cache"]
  end

  %% ===== Memory & Storage =====
  subgraph M["Memory Subsystem"]
    RAM["Physical Memory (DRAM)"]
    DISK["Storage (SSD/HDD)"]
  end

  IO["I/O Devices\n(timer, NIC, disk)"]

  %% ------ Scheduling & Dispatch ------
  T1 -->|Runnable| RQ
  T2 -->|Runnable| RQ
  T3 -->|Runnable| RQ
  RQ --> SCH -->|dispatch next thread| CS -->|load thread context| PC

  %% ------ Instruction Flow & Address Translation ------
  PC --> IFU -->|"instruction fetch (VA)"| TLB -->|PA| L1 --> RAM

  %% ------ Syscalls / Traps / Interrupts ------
  IFU -->|syscall/trap| SYSC
  IO -->|interrupt| SYSC
  SYSC --> SCH

  %% ------ Paging / Swapping (conceptual) ------
  RAM <-->|"page in/out"| DISK
```
프로그램에는 반드시 시작 지점이 있다. 우리가 흔히 main을 시작으로 생각하지만, 실제 실행 흐름은 조금 더 이르다.
운영 체제는 실행 파일을 메모리에 매핑하고, 초기 레지스터와 스택을 준비한 뒤 엔트리 포인트(예: _start)로 점프한다.
런타임이 인자(argc/argv/envp)를 설정한 다음에야 main을 호출하고, main이 끝나면 종료 루틴을 통해 프로그램이 정리된다.

만약 OS 없이 이 과정을 처리한다면, 프로그램을 올릴 메모리 영역을 직접 확보하고, 레지스터/스택 초기화, 진입 주소 결정, 디스크에서 코드 적재 같은 모든 작업을 스스로 구현해야 한다.
현대 운영 체제는 이 수고를 대신하고, 더 나아가 프로세스와 스레드를 만들고 스케줄링하며, 가상 메모리와 시스템 콜로 실행 환경을 제공한다.

그렇다면 싱글 코어 CPU에서 OS는 어떻게 여러 작업과 사용자 프로그램을 "동시에" 실행하는것 처럼 보일까?

### 동시성과 병렬성
그 방법은 **동시성(Concurrency)** 처리다. 나아가 멀티 코어 CPU에서는 **병렬성(Parallelism)** 을 활용한다.  
현대 운영체제는 동시성 프로그램을 만들기 위해 세 개의 기본 접근방법을 제공한다.
- 프로세스. 이 방법에서, 각 논리적 흐름은 OS 커널이 스케줄하고 관리하는 프로세스다. 프로세스가 별도의 가상 주소공간을 가지기 때문에, 서로 통신하기를 원하는
  흐름들은 모종의 명시적 프로세스 간 통신(Interprocess Communication, IPC) 메커니즘을 사용해야 한다.
- I/O 다중화. 이것은 동시성 프로그래밍의 한 형태로, 응용들은 명시적으로 자신의 논리흐름을 한 개의 프로세스 컨텍스트 내에서 스케줄한다.
  논리적 흐름들은 파일 식별자에 도착하는 데이터로 인해 메인 프로그램이 명시적으로 하나의 상태에서 다른 상태로 전환하는 상태 머신으로 모델할 수 있다.
  프로그램이 한 개의 프로세스이므로 모든 흐름들은 동일한 주소공간을 공유한다.
- 스레드. 쓰레드는 한 개의 프로세스 컨텍스트에서 돌아가는 논리적 흐름으로 커널에 의해서 스케줄된다.
  스레드를 다른 두 개의 방식의 하이브리드 형태로 생각할 수 있으며, 프로세스 흐름처럼 커널에 의해서 스케줄되며 I/O 다중화 흐름처럼 동일한 가상 주소공간을 공유한다.

동시성은 한 코어에서 짧은 시간 단위로 작업을 **교대로 실행(Context Switching)** 하여, 여러 일이 "함께 진행되는 것처럼" 보이게 하는 방법이다.  
예를 들어 A, B, C 세 작업이 차례로 아주 빠르게 번갈아 실행되면, 사용자 눈에는 동시에 돌아가는 것처럼 느껴진다.
```mermaid
 flowchart LR
   A[실행 중: 스레드 A] -->|타이머 인터럽트/시스템콜| SAVE[Context 저장: A의 PC/SP/레지스터]
   SAVE --> RQ["레디 큐(Ready Queue)"]
   RQ -->|스케줄러 선택| LOAD[Context 복구: B의 PC/SP/레지스터]
   LOAD --> B[실행 중: 스레드 B]
```
**병렬성(Parallelism)** 은 여러 코어(혹은 여러 CPU)에서 정말로 동시에 서로 다른 작업을 실행하는 것이다.  
동시성을 활용해 시스템을 더 빠르게 만들 수도 있지만, 실제 속도 향상은 병렬성이 있을 때 더 분명해진다.
- 멀티 코어 시스템에서는 여러 코어가 서로 다른 스레드를 동시에 실행한다. 스케줄러는 레디 큐의 스레드를 각 코어에 배치하고, 실제 병렬 실행은 코어가 수행한다.
  이로써 CPU 자원을 효율적으로 활용할 수 있다.
- 멀티 프로세스와 IPC  
  프로세스는 서로 다른 가상 주소 공간을 가지므로 기본적으로 메모리를 공유하지 않는다.
  데이터를 주고받으려면 프로세스 간 통신(IPC)—파이프, 소켓, 메시지 큐, 또는 공유 메모리(+동기화)—가 필요하다. 이 때문에 프로그래밍 복잡도가 높아지며,
  생성·전환 비용도 스레드에 비해 대체로 더 크다.
- 스레드(프로세스 → 스레드로의 진화)  
  이런 한계를 완화하기 위해 같은 프로세스 안에서 메모리를 공유하며 동시에 실행되는 여러 흐름을 두는 스레드가 도입되었다.
  스레드는 코드/데이터/힙을 공유하므로 협업이 빠르고, 생성과 전환 비용도 프로세스보다 작다.
  중요한 점은, 같은 상태를 공유하면서 동시에 실행하는 것이다. 싱글 코어에서는 스케줄러가 스레드들을 교대로 실행해 동시성을 제공하고,
  멀티 코어에서는 여러 스레드가 진짜 동시에 실행되어 병렬성이 실현된다.
    - CPU가 여러개인 상태에서는 공유 프로세스 주소 공간에서 동일한 프로세스에 속한 명령어를 동시에 실행할 수 있다.
      다시 말해 하나의 프로세스 안에 여러 실행 흐름이 존재할 수 있다. (예제 코드를 보면 이해하기 훨씬 편하다.)
      ```text
      int x = 0;
      int y = 0;
      
      void funcA() {
          resA = 1;
      }
      
      void funcB() {
          resB = 2;
      }
      
      int main() {
        thread t1(funcA);
        thread t2(funcB); 
        // join은 스레드가 끝날 때까지 기다리는 함수  
        t1.join(); 
        t2.join(); 
        print(resA + resB); // 3
      }
      ```
      각 함수를 스레드로 실행하면, funcA와 funcB가 동시에 실행될 수 있다. 이때, resA와 resB는 각각 스레드가 공유하는 메모리 공간에 저장된다.
      스레드 t1이 funcA를 실행하면서 resA에 1을 저장하고, t2가 funcB를 실행하면서 resB에 2를 저장한다.
      이후 t1과 t2가 join을 통해 종료될 때까지 기다린다. 마지막으로, main 함수에서 resA와 resB를 더해 3을 출력한다.
      이 예제는 스레드가 어떻게 동시에 실행되면서도 공유 메모리 공간을 통해 협력하는지를 보여준다. 스레드라는 개념을 이용해, 프로세스를 시작하고 스레드 여러 개를 생성하면 다중 코어를 충분히 활용할 수 있다.
      이것이 높은 동시성을 제공하는 프로그래밍의 기본이다.
    - 각 스레드가 프로세스의 메모리 주소 공간을 공유하기 때문에 IPC와 같은 복잡한 통신 메커니즘이 필요 없다.
      이것은 프로그래머에게 큰 편의성을 제공하지만, 많은 문제를 일으키기도 한다. 다중 스레드가 공유 리소스에 접근할 때 오류가 발생하는 것은
      CPU가 명령어를 실행할 때 스레드를 전혀 고려하지 않기 때문이다. 따라서 프로그래머는 상호 배제(Mutual Exclusion)와 동기화(Synchronization)를
      통해 다중 스레드 공유 문제를 명시적으로 직접 해결해야 한다.

요약하면, 운영 체제는 누가 CPU를 언제 쓸지를 정하고(스케줄링), CPU는 프로그램 카운터(PC) 가 가리키는 주소에서 명령어를 가져와 실행한다(명령어 사이클).
이때 싱글 코어에서는 동시성으로, 멀티 코어에서는 동시성과 병렬성을 함께 사용해 사용자에게 빠르고 매끄러운 실행 경험을 제공한다.

### 스레드와 메모리 구조
함수가 실행될 때 필요한 정보는 함수의 매개변수, 지역 변수, 반환 주소 등이 있다. 이런 정보는 **스택 프레임(stack frame)** 에 저장되며,
모든 함수는 실행 시에 자신만의 실행 시간 스택 프레임(runtime stack frame)을 갖는다. 함수가 실행될 때, 스택 프레임은 스택에 쌓이고,
함수가 끝나면 스택에서 제거된다. 이런 스텍 프레임의 증감이 프로세스 주소 공간에서 스택 영역을 형성한다.

스레드는 실행 컨텍스트의 자원 공유 수준을 사용자가 정의할 수 있는 수준으로 다루어 동시성을 제공한다.
프로세스는 실행 시 정보를 저장하는 스택영역이 하나만 있으면 됐다.
실행 흐름 여러 개를 가지는 프로세스는 스택 영역을 여러 개 가지게 된다.(스레드를 여러개 실행하는 프로세스는 스택 영역을 여러 개 가지게 된다.)
또 프로세스의 주소 공간에 각 스레드를 위한 스택영역이 별도로 있어야 한다.

```mermaid
flowchart TB
  subgraph VA["Process Virtual Address Space (conceptual)"]
    direction TB
    subgraph ST["Thread Stacks"]
      direction TB
      Tmain["Main Thread Stack"]:::stack
      T1["Thread t1 Stack (funcA)"]:::stack
      T2["Thread t2 Stack (funcB)"]:::stack
    end
    Gap["Free / Mapped (e.g., Shared Libs)"]:::gap
    Heap["Heap (malloc/new)"]:::heap
    Data["Data Segments (.data / .bss / .rodata)"]:::data
    Text["Code Segment (.text)"]:::text

    Tmain --- T1
    T1 --- T2
    T2 --- Gap
    Gap --- Heap
    Heap --- Data
    Data --- Text
  end

  linkStyle 0,1,2,3,4,5 stroke-width:0;

  classDef stack fill:#e3f2fd,stroke:#1565c0,color:#0b3d91
  classDef heap  fill:#fff3e0,stroke:#ef6c00,color:#5d4037
  classDef data  fill:#e8f5e9,stroke:#2e7d32,color:#1b5e20
  classDef text  fill:#f3e5f5,stroke:#6a1b9a,color:#4a148c
  classDef gap   fill:#f5f5f5,stroke:#9e9e9e,stroke-dasharray:4 4,color:#616161
```
스레드가 처리해야 하는 작업은 긴 작업과 짧은 작업으로 나눌 수 있다.
- 작업 예시:
    - 긴작업: Word 문서 편집 후 디스크에 저장. 이런 디스크 기록 스레드의 수명 주기와 Word 기반 프로세스의 수명 주기는 같음.
    - 짧은 작업: 키 입력 처리/커서 이동, 현재 문장만 맞춤법 체킹, 작은 증분(auto-save delta) 기록 등등
- 이에 따라 생기는 문제
    - 스레드 생성과 종료에 많은 시간을 허비
    - 독립적인 스택 영역을 계속해서 생성하다 보면 리소스 낭비가 심함
    - 짧은 작업이 많아지면 스레드가 자주 생성되고 종료되어 CPU 캐시가 자주 비워짐
- 이를 해결하기 위해 스레드 풀이 생김

스레드 작업 제출과 워커 스레드 실행. 대기열을 사용하고 생산자-소비자 패턴을 따른다.
```mermaid
flowchart LR
    %% 스레드 풀 구조
    subgraph ThreadPool["스레드 풀"]
        direction TB
        Worker1["워커 스레드 1"]
        Worker2["워커 스레드 2"]
        Queue["작업 큐"]
    end
    %% 작업 제출
    subgraph Producer["작업 제출"]
        direction TB
        Submitter["작업 제출자"]
        Submitter -->|작업 제출| Queue
    end
    %% 워커 스레드가 큐에서 작업을 가져와 실행
    Worker1 -->|작업 가져오기| Queue
    Worker2 -->|작업 가져오기| Queue
    Queue -->|작업 실행| Worker1
    Queue -->|작업 실행| Worker2
    %% 결과 전달
    Worker1 -->|결과/콜백 전달| Submitter
    Worker2 -->|결과/콜백 전달| Submitter
```
- 호출자가 작업을 큐에 넣음.
- 풀의 워커가 큐에서 작업을 꺼내 수행. 완료 후 결과/콜백을 게시.

## 2. 스레드 간 공유되는 프로세스 리소스
### 개별 스레드 전용 리소스는 무엇이 있을까?
- 스레드 ID: 각 스레드는 고유한 식별자를 가진다.
- 스택: 각 스레드는 독립적인 스택을 가지며, 함수 호출 시 지역 변수와 반환 주소를 저장한다.
- 프로그램 카운터(PC): 각 스레드는 자신의 프로그램 카운터를 가지며, 현재 실행 중인 명령어의 주소를 가리킨다.
- 스택 포인터(SP): 현재 스레드의 스택 위치를 가리키는 포인터로, 함수 호출 시 스택 프레임을 관리한다.
  이런 정보를 통틀어 스레드 상황정보(Thread Context)라고 한다. 전용 리소스를 제외한 나머지는 스레드 간의 공유되는 리소스에 해당한다.

### 스레드가 공유하는 프로세스 리소스는 무엇이 있을까?
스레드는 프로세스의 주소 공간을 공유한다. 즉, 스택을 제외한 코드, 데이터, 힙 영역을 모두 공유한다.
코드 영역에는 프로그래머가 작성한 코드가 컴파일 된 후 생성된 '실행 가능한 기계 명령어'가 저장된다.
- 코드 영역: 스레드 간에 공유되므로 어떤 함수든지 모든 스레드에 적재하여 실행할 수 있다. 단, 코드 영역은 읽기 전용이므로 스레드가 코드를 수정할 수는 없다.
- 데이터 영역: 전역 변수가 저장되는 곳이다. 프로그램이 실행되는 동안 데이터 영역 내에 전역 변수의 인스턴스(instance)가 하나만 존재하며,
  모든 스레드는 이 전역 변수에 접근할 수 있다. 즉, 어떤 스레드가 이 전역 변수 값을 변경하면 이후 다른 스레드도 변경된 값을 읽게 된다.
- 힙 영역: C/C++에서 동적 메모리 할당을 위해 사용되는 영역이다. malloc 이나 new 연산자를 통해 할당된 메모리는 힙 영역에 저장된다.
  모든 스레드는 포인터(pointer)를 통해 포인터가 가리키는 데이터에 접근할 수 있다.
- 스택영역: 서로 다른 프로세스의 주소 공간은 서로 격리되어 있으며, 가상 메모리 시스템은 특별한 경우를 제외하고 다른 프로세스의 주소 공간에 속한 데이터에 직접
  접근하지 못하도록 보장한다. 하지만, 서로 다른 스레드의 스택 영역 간에는 이런 보호가 없다. 따라서 스레드가 다른 스택 프레임에서 포인터를 가져올 수 있다면
  해당 스레드는 다른 스레드의 스택 영역을 직접 읽고 쓸 수 있다. (수많은 문제를 일으킬 가능성이 높다.)

### 동적 링크 라이브러리와 파일
동적 링크에는 실행 파일에 종속된 라이브러리의 코드와 데이터가 포함되어 있지 않기 때문에 프로그램을 시작할 때 또는 실행 중일 때 종속된 라이브러리의
코드와 데이터를 찾아서 프로세스 주소 공간에 넣는 링크 과정이 완료되어야 한다. 이 데이터와 코드는 프로세스 주소 공간에서 여유공에 적재된다.
즉, 프로세스 내 모든 스레드가 동적 링크 라이브러리의 코드와 데이터를 공유한다.

### 스레드 전용 저장소
이 영역에 저장된 변수는 모든 스레드에서 접근할 수 있지만, 각 스레드가 독립적으로 값을 유지한다.  
아래는 c++에서 thread_local 키워드 사용하여 스레드 전용 저장소를 선언하는 예시 코드다.  
[online compiler](https://www.onlinegdb.com/online_c++_compiler)에서 실행해볼 수 있다.
```cpp
#include <iostream>
#include <thread>

thread_local int a = 1;  // each thread gets its own 'a'

void print_a(const char* who) {
    std::cout << who << " (tid=" << std::this_thread::get_id() << "): a=" << a << '\n';
}

void run(const char* who) {
    ++a;                  // this thread's 'a': 1 -> 2
    print_a(who);         // expect "a=2" per worker thread
}

int main() {
    print_a("main(before)"); // main thread's 'a' == 1

    std::thread t1(run, "t1");
    std::thread t2(run, "t2");
    t1.join();
    t2.join();

    print_a("main(after)");  // still 1 in main (unchanged)
}
```
위와 같이 스레드 전용 저장소로 선언된 변수는 각 스레드가 독립적으로 값을 유지한다. 실행 결과는 다음과 같다.
```text
main(before) (tid=123597973690176): a=1
t1 (tid=123597973685952): a=2
t2 (tid=123597965293248): a=2
main(after) (tid=123597973690176): a=1


...Program finished with exit code 0
Press ENTER to exit console.


```

## 3. 스레드 안전 코드는 도대체 어떻게 작성해야 할까?
이 section 내용은 2장에서 다룬 내용과 유사하다.
### 스레드 안전(Thread Safety)
다중 스레드를 학습할 때는 스레드 안전(Thread Safety)과 동기화(Synchronization) 개념을 이해하는 것이 중요하다.
스레드 안전을 위해서는 공공 자원을 사용할 때 적용되는 제약 조건이 있다.
- **상호 배제(Mutual Exclusion)**: 공유 자원에 동시에 접근하는 것을 방지한다.  
  예를 들어, 두 스레드가 동시에 전역 변수를 수정하려고 할 때, 한 스레드가 작업을 완료할 때까지 다른 스레드가 기다리도록 한다.
- **동기화(Synchronization)**: 스레드 간의 작업 순서를 조정한다.  
  예를 들어, 한 스레드가 데이터를 준비한 후 다른 스레드가 그 데이터를 사용하도록 보장한다.

전용 리소스를 사용하는 스레드는 스레드 안전을 달성할 수 있다.
공유 리소스를 사용하는 스레드는 다른 스레드에 영향을 주지 않도록 하는 대기 제약 조건에 맞게 공유 리소스를 사용하면 스레드 안전을 달성할 수 있다.

스레드 안전이란, 코드가 스레드 몇 개에서 호출되든 이 스레드들이 어떤 순서로 호출되든 간에 상관없이 올바른 결과가 나오는 것을 의미한다.
스레드의 전용 리소스와 공유 리소스에 어떤 것들이 있는지 파악해야 스레드에 안전한 코드를 작성할 수 있다.
공유 리소스는 정수처럼 단순한 변수일 수도 있고 구조체처럼 데이터일 수도 있습니다. 
가장 중요한 점은 이런 리소스를 여럿 리소스에서 읽고 쓸 수 있어야 한다는 것이며, 이 조건을 만족해야만 공유 리소스라고 할 수 있다.

### 스레드 전용 리소스와 공유 리소스
함수의 지역 변수, 스레드의 스택 영역, 스레드 전용 저장소는 스레드 전용 리소스에 해당한다. 그 외의 영역은 공유 리소스로 다음과 같이 구성된다.
- 힙 영역: 메모리의 동적 할당에 사용되는 영역.
- 데이터 영역: 전역 변수가 저장되는 영역.
- 코드 영역: 이 영역은 읽기 전용으로, 프로그램이 실행되는 동안은 코드를 수정할 방법이 없으므로 스레드 안전을 걱정할 필요가 없다.

이런 공유 리소스를 사용하는 스레드는 반드시 순서를 따라야 하며, 순서의 핵심은 공유 리소스를 사용하는 작업이 다른 스레드를 방해할 수 없다는 것이다.
잠금(lock)이나 세마포어(semaphore) 같은 장치를 사용할 수 있다. 이 목적은 스레드 순서를 유지하는 것이다.

```text
int func() {
    int x = 0; // 스레드 전용 리소스
    x = x + 1; // 스레드 전용 리소스에 대한 작업
    return x; // 스레드 전용 리소스 반환
}
위 코드는 스레드의 스택 영역에서 관리되는 지역 변수만 사용한다. 스레드 전용 리소스를 사용하므로 스레드 안전하다.
만약 매개변수를 값으로 전달(call by value)하는 경우라면 어떨까?
```

```text
int func(int x) {
    x = x + 1; // 매개변수 x는 스레드 전용 리소스
    return x; // 스레드 전용 리소스 반환
}
``` 
전달된 매개변수도 스택 영역에 있는 스레드 전용 리소스이기에 스레드 안전하다.

하지만, 포인터를 전달하면 상황은 달라진다.
```text
int global_num = 1;

int func(int* x) {
    *x = *x + 1; // x는 공유 리소스
    return *x; // 공유 리소스 반환
}

void thread_func1() {
    fuc(&global_num); // 전역 변수의 주소를 전달
}

void thread_func2() {
    func(&global_num); // 전역 변수의 주소를 전달
}

```
이 시점에서 `global_num`은 공유 리소스가 된다. 
포인터를 획득할 수 있는 한, 모든 스레드가 포인터가 가리키는 해당 데이터에 접근할 수 있기 때문에 문제가 될 수 있다. 
따라서 스레드 안전인 코드를 작성하는 원칙 중 하나는 스레드 간에 공유 리소스를 사용하지 않도록 가능한 한 모든 조치를 취하는 것이다.

전역변수를 사용하는 경우에도 `__thread_local` 키워드(cpp에서 사용되는 키워드)와 같이 전용 저장소를 만들어 사용하면 스레드 안전이 된다.

### 함수 반환값
함수가 값을 반환하는 경우(return by value)와 함수가 포인터를 반환하는 경우(return by reference) 두 가지가 있다.
```text
int* func() {
    static int a = 100;
    return &a; // 스레드 안전하지 않음
}
```
이 함수는 정적 지역 변수(static local variable) `a`의 주소를 반환한다.
정적 지역 변수는 프로그램이 종료될 때까지 메모리에 유지되므로, 이 함수는 스레드 안전하지 않다.
스레드가 이 함수를 호출하면, 스레드 1이 `a`의 값을 100에서 200으로 변경하고, 스레드 2가 `a`의 값을 200에서 300으로 변경할 수 있다.
이런 상황은 스레드 안전하지 않다. 따라서 함수가 포인터를 반환하는 경우, 반환되는 포인터가 가리키는 데이터가 스레드 전용 리소스인지 확인해야 한다.

### 스레드 안전을 위한 접근 방법
- 스레드 전용 저장소(thread local storage): 전역 리소스를 사용해야 하는 경우 스레드 전용 저장소로 선언할 수 있는지 확인해 봅니다. 이런 종류의 변수는 모든 스레드에서 사용할 수 있지만 각 스레드마다 자체 복사본이 있으며, 이를 변경하더라도 다른 스레드에는 영향을 미치지 않기 때문입니다.
- 읽기 전용(read-only): 전역 리소스를 반드시 사용해야 한다면 해당 전역 리소스를 읽기 전용으로 사용해도 되는지 확인해 봅니다. 다중 스레드에서 읽기 전용 전역 리소스를 사용하더라도 스레드 안전 문제가 발생하지 않습니다.
- 원자성 연산(atomic operation): C++ 언어의 std::atomic 형식의 변수처럼 원자성 연산은 도중에 중단되지 않습니다. 따라서 이런 변수에 대한 연산에는 전통적인 방식의 잠금으로 보호가 필요하지 않습니다.
- 동기화 시 상호 배제(mutual exclusion in synchronization): 이 단계까지 내려왔다면, 한 번에 하나의 스레드만 공유 리소스에 접근할 수 있도록 스레드가 접근하는 공유 리소스 순서를 프로그래머가 어쩔 수 없이 직접 유지해야 하는 상황까지 내몰린 것이 확실합니다. 뮤텍스(mutex), 스핀 잠금(spin lock), 세마포어(semaphore) 외에 여러 가지 동기화 시 상호 배제를 위한 작동 방식 모두가 이 목적을 이루는 데 사용될 수 있습니다.

여기에서 말하는 스레드는 기본적으로 **커널 스레드(kernel thread)** 를 의미다. 커널 스레드는 스레드의 생성, 스케줄링, 종료를 모두 운영 체제가 수행한다.
프로그래머는 스레드가 어떻게 생성되고 스케줄링되는지 전혀 관여할 수 없다는 의미다. 
운영 체제에 의존하지 않는 상황에서 직접 스레드를 구현할 수 있을까? 스레드보다 더 가벼운 실행 흐름인 코루틴을 사용하는 방법이 있다.

## 4. 프로그래머는 코루틴을 어떻게 이해해야 할까?
코루틴과 일반 함수에 형식적인 차이는 없어보이지만, 코루틴에는 스레드와 유사한 기능인 일시 중지와 재개 기능이 있다.
코루틴은 자신의 실행 상태를 저장할 수 있기 때문에 코루틴이 반환된 후에도 계속 호출이 가능하며, 마지막으로 일시 중지된 지점에서 다시 실행된다.
프로그래밍 언어에서 일반적으로 코루틴을 구현하는 방법은 `yield` 키워드를 사용하는 것이다.
```text
def func():
    print("a")
    일시 중지 및 반환
    print("b")
    일시 중지 및 반환
    print("c")
```
파이썬 예제 코드:
```python
def func():
    print("a")
    yield  # 첫 번째 일시 중지 및 반환
    print("b")
    yield  # 두 번째 일시 중지 및 반환
    print("c")
    yield  # 세 번째 일시 중지 및 반환


# 제너레이터 객체 생성
gen = func()

# 한 단계씩 실행 (next를 호출할 때마다 다음 yield까지 실행됨)
print(">>> First call")
next(gen)   # "a" 출력 후 멈춤

print(">>> Second call")
next(gen)   # "b" 출력 후 멈춤

print(">>> Third call")
next(gen)   # "c" 출력 후 멈춤

print(">>> Fourth call")
try:
    next(gen)   # 더 이상 yield가 없어서 StopIteration 발생
except StopIteration:
    print("Generator finished")
```
출력 내용:
```text
>>> First call
a
>>> Second call
b
>>> Third call
c
>>> Fourth call
Generator finished
```

코루틴이 일반 함수와 다른 점은, 코루틴은 실행 상태를 유지하고 일시 중지할 수 있다는 것이다.
이런 특성 덕분에 코루틴은 비동기 프로그래밍, 이벤트 기반 프로그래밍, 또는 협력적 멀티태스킹에 유용하다.
코루틴은 스레드보다 가벼운 실행 흐름으로, 스레드보다 더 적은 오버헤드로 실행할 수 있다.
또한, 코루틴은 스레드와 달리 운영 체제의 스케줄링에 의존하지 않고, 프로그래머가 직접 스케줄링을 제어할 수 있다.
이런 특성 덕분에 코루틴은 비동기 프로그래밍에서 매우 유용하다. 예를 들어, I/O 작업을 수행하는 동안 다른 작업을 계속 진행할 수 있다.
코루틴은 스레드와 달리 운영 체제의 스케줄링에 의존하지 않고, 프로그래머가 직접 스케줄링을 제어할 수 있다.

컴퓨터 시스템은 주기적으로 타이머 인터럽트(timer interrupt)를 생성하고, 인터럽트가 처리될 때마다 운영 체제는 현재 스레드의 일시 중지 여부를 결정할 기회를 가집니다. 
이것이 바로 프로그래머가 명시적으로 스레드를 언제 일시 중지시키고 CPU의 리소스를 내어 줄지 지정할 필요가 없는 이유입니다.  
그러나 사용자 상태(user mode)에서는 타이머 인터럽트를 위한 작동 방식이 없기 때문에 여러분은 코루틴에서 반드시 yield와 같은 예약어를 사용하여 
어디에서 일시 중지하고 CPU의 리소스를 내어 줄 것인지 명시적으로 지정해야 합니다.
반드시 유의할 점은 코루틴 몇 개를 생성하든 관계없이 운영 체제는 이를 알지 못한다는 것입니다. 
코루틴은 온전히 사용자 상태 내에서 구현된 것이기 때문에 코루틴을 사용자 상태 스레드로 해석할 수 있습니다.

### 코루틴은 어떻게 구현될까?
코루틴은 일시 중지되거나 다시 시작될 수 있으며, 일시 중지될 때의 상태 정보를 반드시 기록해야 한다. 이를 기반으로 코루틴을 다시 시작한다.
상태 정보에는 CPU의 레지스터 정보, 함수 실행 시 상태 정보가 포함된다. 이는 `함수`의 `스택 프레임`에 저장된다.
자, 프로세스 주소 공간의 스택 영역은 스레드를 위한 공간이다. 그렇다면 코루틴의 스택 프레임 정보는 어디에 저장될까? 
`힙 영역`에 코루틴의 실행 시간 스택 프레임 정보를 저장한다.

<img src="./images/coroutine_stackframe.jpg" alt="코루틴 스택 프레임을 힙 영역에 저장하는 그림" width="600">

프로세스 주소 공간의 최상단 스택 영역은 함수 스택 프레임을 보관 하는데 사용되며, 이 함수는 코루틴이 아닌 일반 함수를 의미한다.
코루틴의 중요한 역할 중 하나는 바로 프로그래머가 동기 방식으로 비동기 프로그래밍을 가능하게 한다는 것이다.
코루틴은 일반 함수와 유사하게 호출되지만, 실행 중에 일시 중지하고 다시 시작할 수 있는 기능이 있다.
여기까지는 기본적인 추상화 개념인 운영인 운영 체제와 프로세스, 스레드, 코루틴을 봤다. 
이런 추상화된 내용의 개념이 '무엇'인지, '왜' 생겨났는지에 살펴봤는데, 다음 내용 부터는 '어떻게' 사용하는 것인지에 관해 배우게 된다.
